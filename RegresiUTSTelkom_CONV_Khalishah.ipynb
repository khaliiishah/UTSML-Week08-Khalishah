{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogiBs8w8OMYM",
        "outputId": "0f9f180f-d180-4c7c-ebe0-928c2df6055a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from the specified file path\n",
        "file_path = \"/content/drive/MyDrive/RegresiUTSTelkom.csv\"\n",
        "try:\n",
        "    data = pd.read_csv(file_path)\n",
        "    print(\"Dataset successfully loaded!\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found at {file_path}. Please verify the file path and try again.\")\n",
        "    exit()\n",
        "\n",
        "# Rename all columns to a consistent naming format (x1, x2, ..., xn)\n",
        "column_names = [f'x{i+1}' for i in range(data.shape[1])]\n",
        "data.columns = column_names\n",
        "print(\"Columns renamed successfully to:\", column_names)\n",
        "\n",
        "# Display basic information about the dataset and preview the first few rows\n",
        "print(\"Dataset Information:\")\n",
        "print(data.info())\n",
        "print(\"\\nFirst five rows:\")\n",
        "print(data.head())\n",
        "\n",
        "# Generate descriptive statistics for the dataset\n",
        "print(\"\\nDescriptive statistics:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Remove duplicate rows from the dataset\n",
        "data = data.drop_duplicates()\n",
        "print(f\"Duplicates removed. The dataset now contains {data.shape[0]} rows and {data.shape[1]} columns.\")\n",
        "\n",
        "# Separate the target column ('x1') from the rest of the dataset\n",
        "try:\n",
        "    target = data['x1']\n",
        "    data = data.drop(columns=['x1'])\n",
        "    print(\"Target column 'x1' successfully separated.\")\n",
        "except KeyError:\n",
        "    print(\"Target column 'x1' not found in the dataset.\")\n",
        "    exit()\n",
        "\n",
        "# Identify and select features with correlation above a defined threshold\n",
        "correlation_threshold = 0.1\n",
        "correlation_with_target = data.corrwith(target).abs()\n",
        "selected_features = correlation_with_target[correlation_with_target > correlation_threshold].index\n",
        "\n",
        "if selected_features.empty:\n",
        "    print(\"No features found with correlation above the threshold.\")\n",
        "    exit()\n",
        "else:\n",
        "    data_selected = data[selected_features]\n",
        "    print(f\"Selected features based on correlation threshold: {selected_features.tolist()}\")\n",
        "\n",
        "# Apply variance thresholding to remove features with low variance\n",
        "variance_threshold = 0.1\n",
        "selector = VarianceThreshold(threshold=variance_threshold)\n",
        "try:\n",
        "    data_high_variance = selector.fit_transform(data_selected)\n",
        "    print(\"Low variance features removed successfully.\")\n",
        "except ValueError:\n",
        "    print(\"Error: No feature met the variance threshold. Consider adjusting the threshold and try again.\")\n",
        "    exit()\n",
        "\n",
        "# Convert the processed array back to a DataFrame\n",
        "data_final = pd.DataFrame(data_high_variance, columns=[col for col, keep in zip(data_selected.columns, selector.get_support()) if keep])\n",
        "print(f\"Dataset now contains {data_final.shape[1]} features after variance thresholding.\")\n",
        "\n",
        "# Reintegrate the target column into the processed dataset\n",
        "data_final['x1'] = target.values[:data_final.shape[0]]\n",
        "print(\"Target column re-added to the processed dataset.\")\n",
        "\n",
        "# Save the processed dataset to a new file\n",
        "processed_file_path = \"/content/drive/MyDrive/RegresiUTSTelkomCONV.csv\"\n",
        "try:\n",
        "    data_final.to_csv(processed_file_path, index=False)\n",
        "    print(\"Processed dataset saved successfully!\")\n",
        "    print(\"File location:\", processed_file_path)\n",
        "except Exception as e:\n",
        "    print(f\"Error saving the processed dataset: {e}\")\n",
        "\n",
        "# Provide a summary of the final dataset\n",
        "print(f\"Final dataset dimensions: {data_final.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3GjpZfpQgzw",
        "outputId": "2c1e57f4-9e01-4fca-e325-1e19d69423cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset successfully loaded!\n",
            "Columns renamed successfully to: ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10']\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 515130 entries, 0 to 515129\n",
            "Data columns (total 10 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x1      515130 non-null  float64\n",
            " 1   x2      515130 non-null  float64\n",
            " 2   x3      515130 non-null  float64\n",
            " 3   x4      515130 non-null  float64\n",
            " 4   x5      515130 non-null  float64\n",
            " 5   x6      515130 non-null  float64\n",
            " 6   x7      515130 non-null  float64\n",
            " 7   x8      515130 non-null  float64\n",
            " 8   x9      515130 non-null  float64\n",
            " 9   x10     515130 non-null  int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 39.3 MB\n",
            "None\n",
            "\n",
            "First five rows:\n",
            "         x1        x2        x3        x4        x5         x6        x7  \\\n",
            "0  48.73215  70.32679 -24.83777   8.76630  26.84939  202.18689 -12.19034   \n",
            "1  50.95714  55.81851 -18.54940  -3.27872  28.70107   13.09302  -7.27994   \n",
            "2  48.24750  36.29772 -26.21683   5.05097  35.63919   -0.01744  -7.20736   \n",
            "3  50.97020  67.09964 -16.81409 -12.48207  11.20673   28.68782 -15.55296   \n",
            "4  50.54767  92.35066 -19.04928  20.67345  20.84154   51.41086  -9.11273   \n",
            "\n",
            "         x8        x9   x10  \n",
            "0  12.59163 -88.37882  2001  \n",
            "1   1.75729 -12.14279  2001  \n",
            "2 -11.63176 -83.15795  2001  \n",
            "3  -4.05003 -47.75605  2001  \n",
            "4   0.51657  -9.41185  2001  \n",
            "\n",
            "Descriptive statistics:\n",
            "                  x1             x2             x3             x4  \\\n",
            "count  515130.000000  515130.000000  515130.000000  515130.000000   \n",
            "mean       43.386243       8.658865      -9.521523      -2.391044   \n",
            "std         6.067918      35.270798      12.858266      14.572838   \n",
            "min         1.749000    -301.005060     -81.794290    -188.214000   \n",
            "25%        39.953433     -11.463113     -18.441185     -10.780267   \n",
            "50%        44.257105      10.476855     -11.187815      -2.047015   \n",
            "75%        47.833555      29.766593      -2.387207       6.508737   \n",
            "max        61.970140     322.851430     166.236890     172.402680   \n",
            "\n",
            "                  x5             x6             x7             x8  \\\n",
            "count  515130.000000  515130.000000  515130.000000  515130.000000   \n",
            "mean       72.654000      23.094815       6.337618      -0.475665   \n",
            "std       107.917949     205.753058      54.977891      37.678001   \n",
            "min     -1711.484000   -7882.823240   -1329.959740    -600.090760   \n",
            "25%        14.478322     -69.684453     -17.315568     -18.716935   \n",
            "50%        56.222440      21.138595       3.957185      -3.296760   \n",
            "75%       116.851028     115.104493      28.017097      14.852220   \n",
            "max      2496.122620    8360.145570    1198.626770     812.424250   \n",
            "\n",
            "                  x9            x10  \n",
            "count  515130.000000  515130.000000  \n",
            "mean        3.156286    1998.396300  \n",
            "std        99.926934      10.931639  \n",
            "min     -1199.004420    1922.000000  \n",
            "25%       -46.434705    1994.000000  \n",
            "50%         2.260140    2002.000000  \n",
            "75%        51.596165    2006.000000  \n",
            "max      2055.039480    2011.000000  \n",
            "Duplicates removed. The dataset now contains 515130 rows and 10 columns.\n",
            "Target column 'x1' successfully separated.\n",
            "Selected features based on correlation threshold: ['x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10']\n",
            "Low variance features removed successfully.\n",
            "Dataset now contains 9 features after variance thresholding.\n",
            "Target column re-added to the processed dataset.\n",
            "Processed dataset saved successfully!\n",
            "File location: /content/drive/MyDrive/RegresiUTSTelkomCONV.csv\n",
            "Final dataset dimensions: (515130, 10)\n"
          ]
        }
      ]
    }
  ]
}